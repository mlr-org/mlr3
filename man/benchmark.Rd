% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/benchmark.R
\name{benchmark}
\alias{benchmark}
\title{Benchmark Multiple Learners on Multiple Tasks}
\usage{
benchmark(tasks, learners, resamplings)
}
\arguments{
\item{tasks}{(\code{list} of \link{Task})\cr
List of objects of type \link{Task}.}

\item{learners}{(\code{list} of \link{Learner})\cr
List of objects of type \link{Learner}.}

\item{resamplings}{(\code{list} of \link{Resampling})\cr
List of objects of type \link{Resampling}.}
}
\value{
\link{BenchmarkResult}.
}
\description{
Runs a benchmark of the cross-product of learners, tasks, and resampling strategies (possibly in parallel).
}
\examples{
tasks = mlr_tasks$mget(c("iris", "sonar"))
learners = mlr_learners$mget(c("classif.dummy", "classif.rpart"))
resamplings = mlr_resamplings$mget(c("holdout", "cv"))
bmr = benchmark(tasks, learners, resamplings)
bmr$performance

# Overview of of resamplings that were conducted internally
hashes = bmr$hashes
print(hashes)

# Extract second resampling
hash = bmr$hashes$hash[2]
rr = bmr$resampling(hash = hash)
print(rr)

# Extract predictions of first experiment of this resampling
rr$experiment(1)$prediction
}
