% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/benchmark.R
\name{benchmark}
\alias{benchmark}
\title{Benchmark Multiple Learners on Multiple Tasks}
\usage{
benchmark(tasks, learners, resamplings, measures)
}
\arguments{
\item{tasks}{[\code{list} of \code{\link{Task}}]\cr
List of objects of type \code{\link{Task}}.}

\item{learners}{[\code{list} of \code{\link{Learner}}]\cr
List of objects of type \code{\link{Learner}}.}

\item{resamplings}{[\code{list} of \code{\link{Resampling}}]\cr
List of objects of type \code{\link{Resampling}}.}

\item{measures}{[\code{list} of \code{\link{Measure}}]\cr
List of objects of type \code{\link{Measure}}.}
}
\value{
\code{\link{BenchmarkResult}}.
}
\description{
Runs a benchmark on the full grid of learners and tasks.
}
\examples{
tasks = lapply(c("iris", "sonar"), mlr_tasks$get)
learners = lapply(c("classif.dummy", "classif.rpart"), mlr_learners$get)
resamplings = lapply("cv", mlr_resamplings$get)
measures = lapply("mmce", mlr.measures$get)
benchmark(tasks, learners, resamplings, measures)
}
