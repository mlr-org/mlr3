---
title: "Introduction to train/predict/score"
author: "Michel Lang"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to train/predict/score}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
library(mlr3)
knitr::opts_knit$set(
  datatable.print.keys = FALSE,
  datatable.print.class = TRUE
)
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

In this introduction we simply fit a classification tree on the iris and determine the mean misclassification error.

## Objects

First, we need to generate retrieve the following `mlr3` objects from the task dictionary and the learner dictionary, respectively:

1. The classification task
    ```{r}
    task = mlr_tasks$get("iris")
    ```
2. A learner for the classification tree
    ```{r}
    learner = mlr_learners$get("classif.rpart")
    ```

## Splitting into train and test

We opt to learn on roughly $\frac{4}{5}$ of the observations and predict on the other $\frac{1}{5}$.
To do so we create two index vectors:
```{r}
train.set = sample(task$nrow, 4/5 * task$nrow)
test.set = setdiff(seq_len(task$nrow), train.set)
```

## Setting up an Experiment

The process of fitting a machine learning model, predicting on test data and scoring the predictions by comparing predicted and true labels is called an experiment.
For this reason, we start by initializing an experiment here, too:
```{r}
e = Experiment$new(task = task, learner = learner)
print(e)
```
The printer also shows a summary of the state of the experiment.


## Training

To train the learner on the task, we call the train function of the experiment:
```{r}
e$train(subset = train.set)
print(e)
```
The printer indicates that the object was grown, we have now stored a model in the experiment (along some more technical stuff like log files):
```{r}
rpart.model = e$model
print(rpart.model)
```

## Predicting

After the training step, we are able to use the experiment to predict on observations of the task (note that you may alternatively also pass new data here as `data.frame`):
```{r}
e$predict(subset = test.set)
print(e)
```
The predictions can be retrieved as a simple `data.table`.
```{r}
head(e$prediction)
```

## Performance Assessment

The last step of the experiment is quantifying the predicted labels by comparing them with the true labels using a performance measure.
The default measure for the iris classification task is the mean misclassification error which is used here automatically:
```{r}
ids(task$measures)
e$score()
print(e)
e$performance["mmce"]
```

The experiment is now "complete" which means we can access all of its methods.


## Chaining methods

Instead of calling the methods `$train()`, `$predict()` and `$score()` one after each other, it is also possible to chain these commands:
```{r}
Experiment$new(task = task, learner = learner)$train(train.set)$predict(test.set)$score()
```
