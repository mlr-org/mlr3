---
title: "Handling model errors"
author: "Michel Lang"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Handling model errors}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE, cache = FALSE}
library(mlr3)
knitr::opts_knit$set(
  datatable.print.keys = FALSE,
  datatable.print.class = TRUE
)

knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
future::plan("sequential")
set.seed(123)
```

This vignettes demonstrates how to deal with learners which raise exceptions during train or predict.

# Setup

First, we need a simple learning task and a learner which raises exceptions.
For this purpose, `mlr3` ships with the learner `classif.crashtest`:
```{r}
task = mlr_tasks$get("spam")
learner = mlr_learners$get("classif.crashtest")
print(learner)
```
The hyperparameters let us control (a) whether it should crash during train or predict, and (b) if the learner should crash with an error or segfault (which tears down the complete R session).
With its default settings, it will throw an exception during the `train` step.


# No Error Handling

In the defaults, `mlr3` does not handle errors.
Thus, the exception raised by the crashtest learner stops the execution and can be tracebacked:

```{r, error = TRUE, eval = -3}
e = Experiment$new(task, learner)
e$train()
traceback()
```

Note that the traceback sometimes is obfuscated by the parallelization framework, i.e. if your entry point in the calculation is via `resample()` or `benchmark()`.
To get a better traceback, you can turn the parallelization completely off by setting the control argument `disable_future`:
```{r}
ctrl = mlr_control(disable_future = TRUE)
```

# Encapsulation

During parallelization, error messages (as well as normal output or warnings) are often not properly forwarded to the master R session, or they arrive in a confusing order.
The learner execution can be encapsulated, so its output is logged to the experiment instead of just printed to the console:
```{r}
ctrl = mlr_control(encapsulate_train = "evaluate")
e = Experiment$new(task, learner, ctrl = ctrl)
e$train()
e$has_errors
e$logs$train
```
You can also enable the encapsulation for the *predict* or *score* steps of an experiment by setting `encapsulate_predict` or `encapsulate_score`, respectively.

Another possibility to encapsulate is execution via package the [`callr`](https://cran.r-project.org/package=callr).
[`callr`](https://cran.r-project.org/package=callr) spawns a new R process, and thus guards us from segfaults.
On the downside, starting new processes comes with a computational overhead.
```{r}
ctrl = mlr_control(encapsulate_train = "callr")
e = Experiment$new(task, learner)
e$train(ctrl = ctrl)
e$has_errors
e$logs$train
```

```{r}
ctrl = mlr_control(encapsulate_train = "callr")
task = mlr_tasks$get("spam")
learner = mlr_learners$get("classif.crashtest")
learner$param_vals = list(crash.on = "train", crash.mode = "segfault")
e = Experiment$new(task, learner)
e$train(ctrl = ctrl)
e$has_errors
e$logs$train$errors
```

Note that, although no exception has been raised with encapsulation, it is impossible to perform the predict step without a model:
```{r, error = TRUE}
e$predict()
```

As a workaround, we define a learner in the next section which is used as a surrogate to create predictions.


# Fallback Learners

Each learner can have a fallback learner, which is used if either the train or predict step fail.
Here, we simply fallback to the predictions of a featureless learner (predicting majority class):

```{r}
task = mlr_tasks$get("spam")
learner = mlr_learners$get("classif.crashtest")
learner$fallback = mlr_learners$get("classif.featureless")
ctrl = mlr_control(encapsulate_train = "evaluate")

e = Experiment$new(task = task, learner = learner, ctrl = ctrl)
e$train()
e$has_errors
e$logs$train

e$predict()
e$score()
e$prediction
e$performance
```

Note that the logs and timings are tracked for the original learner, not the fallback learner.
