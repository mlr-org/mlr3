---
title: "Introduction to Tasks"
author: "Michel Lang"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to Tasks}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
library(mlr3)
knitr::opts_knit$set(
  datatable.print.keys = FALSE,
  datatable.print.class = TRUE
)
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Predefined tasks

`mlr` ships with some predefined, well-known toy tasks.
They are stored in the dictionary (key-value store) `mlr_tasks`.

```{r}
# list keys
mlr_tasks$ids

# retrieve iris task
task = mlr_tasks$get("iris")
```

Several task properties and characteristics can be queried using the task methods.
Many of them should be self-explanatory.

```{r}
print(task)

task$nrow
task$ncol
task$target
task$nclasses
task$classes
task$features
task$head()
```

In `mlr3`, each row has a unique identifier (row name) which can be either `integer` or `character.`
These can be used to select specific rows.
To filter columns, you can just specify the column names.
```{r}
# iris uses integer row_ids
task$row_ids()
task$data(rows = c(1, 51, 101))
task$data(rows = c(1, 51, 101), cols = "Species")
```


## Task Creation

To create a task from a `data.frame`, you must determine the task_type to select the respective constructor:

* Classification Task: Target column is labels (stored as `character`/`factor`) with only few distinct values.
  <br>$\Rightarrow$ `TaskClassif`.
* Regression Task: Target column is numeric (stored as `integer`/`double`).
  <br>$\Rightarrow$ `TaskRegr`.
* Cluster Task: You don't have a target but want to identify similarities in the feature space.
  <br>$\Rightarrow$ Not yet implemented.

Let's assume we want to create a simple regression task using the `mtcars` data set from the package `datasets` to predict the column `"mpg"` (miles per gallon).
We only take the first two features here to keep the output in the following examples short.

```{r}
data("mtcars", package = "datasets")
task = TaskRegr$new(id = "cars", data = mtcars[, 1:3], target = "mpg")
print(task)
```

The row names of `mtcars` are automatically used as row_ids.
```{r}
task$row_ids()
task$data(rows = c("Merc 280", "Volvo 142E"))
```


## Column Roles

Now, we want the original `row.names` of `mtcars` to be a regular column.
Thus, we first pre-process the `data.frame` and then re-create the task.
```{r}
library("data.table")
# `as.data.table` removes rownames, but  argument `keep.rownames` ensures
# that they are stored in a separate column before
data = as.data.table(mtcars[, 1:3], keep.rownames = TRUE)
task = TaskRegr$new(id = "cars", data = data, target = "mpg")

# we now have integer row_ids
task$row_ids()

# there is a new "feature" called "rn"
task$features
```

In `mlr3`, columns (and rows) can have specific roles w.r.t. the learning task.
We have seen three different roles so far:

1. The target column (here `"mpg"`), also called dependent variable.
2. Features, also called independent variables.
3. The row_id. This column is there for technical reasons but is typically useless for learning.

The different roles are listed in the table `cols`:
```{r}
task$cols
```

In the following we do not want to learn on neither the primary key (which is already handled by `mlr3`) nor the new column `rn` with the row names.
However, we still might want to carry it around for different reasons.
E.g., we can use the row names in plots or to associate outliers with the row names.
This being said, we need to change the role of this column to hide it from our learning algorithms.
We change its role to `"ignore"`:
```{r}
task$features
task$cols[id == "rn", role := "ignore"]
task$cols

# "rn" not listed as feature any more
task$ncol
task$features

# also eliminated from "data" and "head"
task$data(rows = 1:2)
task$head(2)

# retrieve columns regardless of their roles
task$data(rows = 1:2, filter_cols = FALSE)
```

## row_roles

Just like columns, you can also assign different roles to rows.
Rows can have three different roles:

1. Role `"training"`:
   Rows that are generally available for model fitting (although they may also be used as test set in resampling).
   This is the default role.
2. Role `"validation"`:
   Rows that are held back (see below).
   Rows which have missing values in the target column upon task creation are automatically moved to the validation set.
3. Role `"ignore"`: Rows that are simply ignored

There are several reasons to hold some observations back or treat them differently:

1. It is often good practice to validate the final model on an external validation set to uncover possible overfitting
2. Some observations may be unlabeled, e.g. in data mining cups or Kaggle competitions.
   These observations cannot be used for training a model, but you can still predict labels.

Instead of creating a task with only a subset of observations and then manually apply the fitted model on an hold-back `data.frame`, you can just call the function `validate()` later on.
Marking observations as validation works analogously to changing column roles:
```{r}
head(task$rows)

task$nrow
task$rows[id %in% 29:32, role := "validation"]
task$nrow
```

All pre- and post-processing you have used on the training data is also applied to the validation data in exactly the same way.
